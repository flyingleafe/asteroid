{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa as lr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from librosa import display as lrd\n",
    "import IPython.display as ipd\n",
    "\n",
    "from torch.utils.data import DataLoader, ConcatDataset, random_split\n",
    "from asteroid.data import TimitDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from asteroid.data.utils import find_audio_files, cut_or_pad\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_wav(wav, sr=16000):\n",
    "    if type(wav) == str:\n",
    "        wav, sr = lr.load(wav)\n",
    "        \n",
    "    lrd.waveplot(wav, sr=sr)\n",
    "    plt.show()\n",
    "    ipd.display(ipd.Audio(wav, rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIMIT_CACHE_DIR = '/import/vision-eddydata/dm005_tmp/mixed_wavs_asteroid'\n",
    "TIMIT_CACHE_DIR = '/jmain01/home/JAD007/txk02/aaa18-txk02/Datasets/mixed_wavs_asteroid'\n",
    "TIMIT_TRAIN_DIR = '/jmain01/home/JAD007/txk02/aaa18-txk02/Datasets/TIMIT'\n",
    "ENV_NOISE_DIR = '/jmain01/home/JAD007/txk02/aaa18-txk02/Datasets/noises-train'\n",
    "DRONE_NOISE_DIR = '/jmain01/home/JAD007/txk02/aaa18-txk02/Datasets/noises-test-drones'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_snrs = [-25, -20, -15, -10, -5, 0, 5, 10, 15]\n",
    "test_snrs = [-30, -25, -20, -15, -10, -5, 0, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing datasets: 100%|██████████| 9/9 [04:26<00:00, 29.60s/it]\n"
     ]
    }
   ],
   "source": [
    "timit_train_misc = TimitDataset.load_with_cache(\n",
    "    TIMIT_TRAIN_DIR,\n",
    "    ENV_NOISE_DIR,\n",
    "    cache_dir=TIMIT_CACHE_DIR, snrs=train_snrs, root_seed=42, prefetch_mixtures=False,\n",
    "    dset_name='train-misc', subset='train', track_duration=48000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timit_train_drones = TimitDataset.load_with_cache(\n",
    "#     '../../../datasets/TIMIT', '../../../datasets/noises-train-drones',\n",
    "#     cache_dir=TIMIT_CACHE_DIR, snrs=train_snrs, root_seed=42, prefetch_mixtures=False,\n",
    "#     mixtures_per_clean=5, dset_name='train-drones',\n",
    "#     subset='train', track_duration=48000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timit_test_drones = TimitDataset.load_with_cache(\n",
    "    TIMIT_TRAIN_DIR,\n",
    "    DRONE_NOISE_DIR,\n",
    "    cache_dir=TIMIT_CACHE_DIR, snrs=test_snrs, dset_name='test-drones',\n",
    "    subset='test', root_seed=68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(ds, val_fraction=0.1, random_seed=42):\n",
    "    assert val_fraction > 0 and val_fraction < 0.5\n",
    "    len_train = int(len(ds) * (1 - val_fraction))\n",
    "    len_val = len(ds) - len_train\n",
    "    return random_split(ds, [len_train, len_val], generator=torch.Generator().manual_seed(random_seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set = train_val_split(timit_train_misc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 10\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "#train_loader_test = DataLoader(train_set, shuffle=True, batch_size=8, num_workers=NUM_WORKERS, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from torch_lr_finder import LRFinder\n",
    "from pytorch_lightning import Trainer, loggers as pl_loggers\n",
    "from asteroid_filterbanks.transforms import mag\n",
    "from asteroid.engine import System\n",
    "from asteroid.losses import singlesrc_neg_sisdr\n",
    "\n",
    "from asteroid import DCUNet, DCCRNet\n",
    "\n",
    "def sisdr_loss_wrapper(est_target, target):\n",
    "    return singlesrc_neg_sisdr(est_target.squeeze(1), target).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcunet20 = DCUNet(\"DCUNet-20\", fix_length_mode=\"trim\")\n",
    "dcunet20_opt = optim.Adam(dcunet20.parameters(), lr=1e-7, weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr_finder = LRFinder(dcunet20, dcunet20_opt, sisdr_loss_wrapper, device=\"cuda\")\n",
    "#lr_finder.range_test(train_loader_test, end_lr=10, num_iter=100)\n",
    "#lr_finder.plot()\n",
    "#lr_finder.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcunet20_sched = optim.lr_scheduler.OneCycleLR(dcunet20_opt, 0.03, epochs=10, steps_per_epoch=len(train_loader))\n",
    "scheduler = {'scheduler': dcunet20_sched, 'interval': 'step'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = System(dcunet20, dcunet20_opt, sisdr_loss_wrapper, train_loader, val_loader, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = pl_loggers.TensorBoardLogger('logs', name='TIMIT-drones-DCUNet-20-onecycle', version='v3')\n",
    "trainer = Trainer(max_epochs=10, gpus=-1, accelerator='dp', logger=logger)\n",
    "trainer.fit(system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcunet20_serialized = dcunet20.serialize()\n",
    "torch.save(dcunet20_serialized, 'dcunet_20_onecycle_v3.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training UNetGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "\n",
    "from asteroid.masknn import UNetGANGenerator, UNetGANDiscriminator\n",
    "\n",
    "def _unsqueeze_to_3d(x):\n",
    "    \"\"\"Normalize shape of `x` to [batch, n_chan, time].\"\"\"\n",
    "    if x.ndim == 1:\n",
    "        return x.reshape(1, 1, -1)\n",
    "    elif x.ndim == 2:\n",
    "        return x.unsqueeze(1)\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "class UNetGAN(pl.LightningModule):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        mse_weight: float = 20,\n",
    "        lr_g: float = 1e-3,\n",
    "        lr_d: float = 1e-3,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # networks\n",
    "        self.generator = UNetGANGenerator()\n",
    "        self.discriminator = UNetGANDiscriminator()\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.generator(_unsqueeze_to_3d(z))\n",
    "\n",
    "    def adversarial_loss(self, y_hat, y):\n",
    "        return F.binary_cross_entropy(y_hat, y)\n",
    "\n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "        mix, clean = batch\n",
    "        mix = _unsqueeze_to_3d(mix)\n",
    "        clean = _unsqueeze_to_3d(clean)\n",
    "\n",
    "        # train generator\n",
    "        if optimizer_idx == 0:\n",
    "\n",
    "            enh = self.generator(mix)\n",
    "            disc_vals = self.discriminator(mix, enh)\n",
    "            \n",
    "            fake = torch.zeros(*disc_vals.size())\n",
    "            fake = fake.type_as(disc_vals)\n",
    "            \n",
    "            mse_loss = F.mse_loss(clean, enh)\n",
    "            adv_loss = -self.adversarial_loss(disc_vals, fake)\n",
    "            \n",
    "            lm = self.hparams.mse_weight\n",
    "            g_loss = adv_loss + lm * mse_loss\n",
    "        \n",
    "            tqdm_dict = {'g_loss': g_loss}\n",
    "            output = OrderedDict({\n",
    "                'loss': g_loss,\n",
    "                'progress_bar': tqdm_dict,\n",
    "                'log': tqdm_dict\n",
    "            })\n",
    "            return output\n",
    "\n",
    "        # train discriminator\n",
    "        if optimizer_idx == 1:\n",
    "            # Measure discriminator's ability to classify real from generated samples\n",
    "\n",
    "            enh = self.generator(mix).detach()\n",
    "            clean_disc_vals = self.discriminator(mix, clean)\n",
    "            enh_disc_vals = self.discriminator(mix, enh)\n",
    "            \n",
    "            # how well can it label as real?\n",
    "            valid = torch.ones(*clean_disc_vals.size())\n",
    "            valid = valid.type_as(clean_disc_vals)\n",
    "            \n",
    "            fake = torch.zeros(*enh_disc_vals.size())\n",
    "            fake = fake.type_as(enh_disc_vals)\n",
    "\n",
    "            real_loss = self.adversarial_loss(clean_disc_vals, valid)\n",
    "            fake_loss = self.adversarial_loss(enh_disc_vals, fake)\n",
    "        \n",
    "            d_loss = real_loss + fake_loss\n",
    "            tqdm_dict = {'d_loss': d_loss}\n",
    "            output = OrderedDict({\n",
    "                'loss': d_loss,\n",
    "                'progress_bar': tqdm_dict,\n",
    "                'log': tqdm_dict\n",
    "            })\n",
    "            return output\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        lr_g = self.hparams.lr_g\n",
    "        lr_d = self.hparams.lr_d\n",
    "\n",
    "        opt_g = torch.optim.Adam(self.generator.parameters(), lr=lr_g)\n",
    "        opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=lr_d)\n",
    "        return [opt_g, opt_d], []\n",
    "\n",
    "#     def on_epoch_end(self):\n",
    "#         z = self.validation_z.type_as(self.generator.model[0].weight)\n",
    "\n",
    "#         # log sampled images\n",
    "#         sample_imgs = self(z)\n",
    "#         grid = torchvision.utils.make_grid(sample_imgs)\n",
    "#         self.logger.experiment.add_image('generated_images', grid, self.current_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unetgan_module = UNetGAN(lr_g=2e-4, lr_d=2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(max_epochs=100, gpus=[1,3], accelerator='ddp',\n",
    "                  resume_from_checkpoint='logs/UNetGAN-misc-continue/v1/checkpoints/epoch=68-step=322712.ckpt')\n",
    "trainer.fit(unetgan_module, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = pl_loggers.TensorBoardLogger('logs', name='TIMIT-misc-DCCRN', version='v2')\n",
    "model2 = DCCRNet(\"DCCRN-CL\")\n",
    "optimizer2 = optim.Adam(model2.parameters(), lr=1e-3)\n",
    "system2 = System(model2, optimizer2, sisdr_loss_wrapper, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(max_epochs=30, gpus=1, logger=logger)\n",
    "trainer.fit(system2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dccrn_serialized = model2.serialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dccrn_serialized, 'dccrn_v2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from asteroid.masknn.wavenet import UNetGANGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = UNetGANGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in gen.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
